{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L6Pw7bn14a8l",
    "pycharm": {}
   },
   "source": [
    "# Laboratorio 2.2: Clasificación\n",
    "\n",
    "Bárbara Poblete, Felipe Bravo, Aymé Arango, Alison Fernandez, Mabel Sánchez, Juan Pablo Silva\n",
    "\n",
    "**Junio 2020**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7r7niHv54a8o",
    "pycharm": {}
   },
   "source": [
    "## ============= Declaración de compromiso ético =============\n",
    "\n",
    "Las siguientes personas: Pía Contreras Guerrero, declaran no incurrir en copia, ni compartir respuestas con otras personas. Por lo que, ratifican que las respuestas de la presente actividad son de su propia confección y reflejan su propio conocimiento.\n",
    "\n",
    "## =========== Contribución de cada integrante del grupo  ==========\n",
    "\n",
    "Sólo en caso de desarrollar el presente laboratorio en grupo (de máximo dos), especifique la contribución:\n",
    "\n",
    "::\n",
    "\n",
    "::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pJs9hrWC4a8o",
    "pycharm": {}
   },
   "source": [
    "# Instrucciones\n",
    "\n",
    "\n",
    "1. Trabaje de manera individual o en grupo de 2 personas. Asegúrese de agregar su(s) nombre(s) en la Declaración de compromiso ético y especificar la contribución de cada integrante en caso de trabajar en grupo.\n",
    "\n",
    "2. Modifique este archivo `.ipynb` agregando sus respuestas donde corresponda. \n",
    "\n",
    "3. Cuando finalice el laboratorio, **genere un archivo HTML** usando jupyter (ver tutorial 2: *Descargar el archivo HTML*) y súbalo a U-Cursos. El laboratorio debe ser entregado por 1 integrante, en caso de trabajar en grupo .\n",
    "\n",
    "4. Las respuestas a cada pregunta se deben escribir en los bloques que dicen **RESPUESTA A PREGUNTA X.X**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MwCpghiN4a8q",
    "pycharm": {}
   },
   "source": [
    "# Del Laboratorio \n",
    "\n",
    "En este laboratorio vamos a comparar clasificadores con cierto *baselines* o clasificadores base, vamos a ver como seleccionar hiperparámetros y además vamos a trabajar con clases desbalanceadas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CfiaJs1i4a8r",
    "pycharm": {}
   },
   "source": [
    "# Parte 1: Comparar clasificadores\n",
    "\n",
    "Una de las principales tareas en enfoques supervisados es evaluar diferentes clasificadores y encontrar el mejor rendimiento de alguno de ellos. Por ejemplo, si tenemos dos (o más) clasificadores y queremos compararlos entre sí, nos interesa responder: *¿Cuál de los clasificadores es el mejor?* \n",
    "Para responder esta pregunta, no existe una única solución. \n",
    "\n",
    "Lo que haremos a continuación será ejecutar diferentes clasificadores y compararlos en base a las métricas de Precision, Recall y F1-score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RS38GcxL4a8t",
    "pycharm": {}
   },
   "source": [
    "## Pregunta 1.1  \n",
    "\n",
    "Para realizar la evaluación de distintos clasificadores, vamos a crear la función `run_classifier()`, la cual evalúa un clasificador `clf` recibido como parámetro, un dataset `X,y` (dividido en training y testing) y un número de tests llamado `num_test`. Esta función almacena y retorna los valores de precision, recall y f1-score en la variable `metrics` además de los resultados de predicción.\n",
    "\n",
    "\n",
    "En base a lo anterior, incluya las sentencias que ajusten el modelo junto a su correspondiente predicción sobre los datos. **No use cross-validation ni tampoco el parámetro `random_state`.**\n",
    "\n",
    "\n",
    "### Respuesta 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T16:36:46.091375Z",
     "start_time": "2020-05-25T16:36:45.318247Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "5ieP3_HX4a8u",
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "### COMPLETAR ESTE CÓDIGO\n",
    "\n",
    "## run_classifier recibe un clasificador y un dataset dividido para entrenamiento y testing\n",
    "## y opcionalmente la cantidad de resultados que se quiere obtener del clasificador\n",
    "\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "def run_classifier(clf, X, y, num_tests=100):\n",
    "    metrics = {'f1-score': [], 'precision': [], 'recall': []}\n",
    "    \n",
    "    for _ in range(num_tests):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.30)\n",
    "        ### INICIO COMPLETAR ACÁ \n",
    "        \n",
    "        #### TIP: en base a los set de entrenamiento, genere la variable 'predictions' \n",
    "        #### que contiene las predicciones del modelo\n",
    "        \n",
    "        clf.fit(X_train, y_train)  \n",
    "        predictions = clf.predict(X_test)\n",
    "\n",
    "    \n",
    "        \n",
    "        ### FIN COMPLETAR ACÁ\n",
    "        \n",
    "        metrics['y_pred'] = predictions\n",
    "        metrics['f1-score'].append(f1_score(y_test, predictions)) \n",
    "        metrics['recall'].append(recall_score(y_test, predictions))\n",
    "        metrics['precision'].append(precision_score(y_test, predictions))\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KrPk4T5-4a8w",
    "pycharm": {}
   },
   "source": [
    "Luego de completar el código anterior, ejecute el siguiente bloque para comparar distintos clasificadores. \n",
    "Usaremos un **dataset de cáncer de mamas** para evaluar. Información del dataset la puede encontrar en el siguiente link: https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T16:36:46.369126Z",
     "start_time": "2020-05-25T16:36:46.094038Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n",
      "Resultados para clasificador:  Base Dummy\n",
      "Precision promedio: 0.6294758808376182\n",
      "Recall promedio: 0.6247223790327502\n",
      "F1-score promedio: 0.6255558199631609\n",
      "----------------\n",
      "\n",
      "\n",
      "----------------\n",
      "Resultados para clasificador:  Decision Tree\n",
      "Precision promedio: 0.9408810170506637\n",
      "Recall promedio: 0.9423928244790095\n",
      "F1-score promedio: 0.9413024402134706\n",
      "----------------\n",
      "\n",
      "\n",
      "----------------\n",
      "Resultados para clasificador:  Gaussian Naive Bayes\n",
      "Precision promedio: 0.9394637036801465\n",
      "Recall promedio: 0.9666818098795342\n",
      "F1-score promedio: 0.9526444207084005\n",
      "----------------\n",
      "\n",
      "\n",
      "----------------\n",
      "Resultados para clasificador:  KNN\n",
      "Precision promedio: 0.9291713301035226\n",
      "Recall promedio: 0.964675739739482\n",
      "F1-score promedio: 0.9463203442932443\n",
      "----------------\n",
      "\n",
      "\n",
      "----------------\n",
      "Resultados para clasificador:  Support Vector Machines\n",
      "Precision promedio: 0.8916936139658956\n",
      "Recall promedio: 0.9821171441402654\n",
      "F1-score promedio: 0.9344375782729207\n",
      "----------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## ejecutar este código\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB  # naive bayes\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC  # support vector machine classifier\n",
    "\n",
    "bc = load_breast_cancer()    # dataset cancer de mamas\n",
    "X = bc.data\n",
    "y = bc.target\n",
    "\n",
    "c0 = (\"Base Dummy\", DummyClassifier(strategy='stratified'))\n",
    "c1 = (\"Decision Tree\", DecisionTreeClassifier(max_depth=5))\n",
    "c2 = (\"Gaussian Naive Bayes\", GaussianNB())\n",
    "c3 = (\"KNN\", KNeighborsClassifier(n_neighbors=10))\n",
    "c4 = (\"Support Vector Machines\", SVC())\n",
    "\n",
    "classifiers = [c0, c1, c2, c3, c4]\n",
    "\n",
    "results = {}\n",
    "for name, clf in classifiers:\n",
    "    metrics = run_classifier(clf, X, y)   # hay que implementarla en el bloque anterior.\n",
    "    results[name] = metrics\n",
    "    print(\"----------------\")\n",
    "    print(\"Resultados para clasificador: \", name) \n",
    "    print(\"Precision promedio:\", np.array(metrics['precision']).mean())\n",
    "    print(\"Recall promedio:\", np.array(metrics['recall']).mean())\n",
    "    print(\"F1-score promedio:\", np.array(metrics['f1-score']).mean())\n",
    "    print(\"----------------\\n\\n\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iR2fbdiU4a83",
    "pycharm": {}
   },
   "source": [
    "### Pregunta 1.2\n",
    "\n",
    "Analizando los resultados obtenidos de cada clasificador, y basándose en las métricas calculadas. ¿Cuál es el mejor clasificador? ¿Qué métricas observó para tomar esa decisión y por qué? Fundamente su respuesta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VqyPHZUI4a84",
    "pycharm": {}
   },
   "source": [
    "### Respuesta 1.2\n",
    ":: \n",
    "\n",
    "El mejor clasificador es Gaussian Naive Bayes pues, al fijarse en la métrica F1-score promedio se puede ver que es el clasificador que tiene el valor más alto (en comparación con los demás F1-score). Se eligió esta métrica puesto que combina precision y recall, por lo tanto se puede tener \"dos métricas en una\".\n",
    "\n",
    "::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 1.3\n",
    "\n",
    "Explique cómo escoge un árbol de decisión el atributo raíz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Respuesta 1.3\n",
    ":: \n",
    "\n",
    "Un nodo raíz es aquel que no tiene arcos entrantes ni arcos salientes. La estrategia es divide y vencerás recursiva, en ocasiones es del tipo categórico.\n",
    "::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 1.4\n",
    "\n",
    "Explique el problema de optimización que resuelve una SVM lineal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Respuesta 1.4\n",
    ":: \n",
    "Se necesita encontrar un hiperplano lineal que separe los ejemplos de positivos de los negativos, para ello existen infintas soluciones, sin embargo queremos un hiperplano que maximice el margen de entrenamiento (menores errores de generalización). Entre más ancho el margen, mayor poder de generalización.\n",
    "\n",
    "SVM lineal es un clasificador que busca  un hiperplano con el máximo margen, para ello se formula un problema de optimización que permita encontrar el hiperplano de máximo margen.\n",
    "\n",
    "::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LhQqOrGs8deT"
   },
   "source": [
    "# Parte 2: Selección de hiperparámetros\n",
    "\n",
    "Los hiperparámetros son parámetros que no se aprenden directamente dentro de los estimadores. En scikit-learn se pasan como argumentos al constructor de las clases, por ejemplo cuál kernel usar para Support Vector Classifier, o qué criterio para Decision Tree, etc. Es posible y recomendable buscar en el espacio de hiperparámetros la mejor alternativa. Cualquier parámetro proporcionado al construir un estimador puede optimizarse de esta manera. Para encontrar los nombres y los valores actuales de todos los parámetros para un estimador dado puede usar *estimator.get_params()*.\n",
    "\n",
    "Una búsqueda consiste en:\n",
    "\n",
    "*   un estimador (regresor o clasificador como sklearn.svm.SVC);\n",
    "*   un espacio de parámetros;\n",
    "*   un método para buscar o muestrear candidatos;\n",
    "*   un esquema de validación cruzada; y\n",
    "*   una función de puntuación(score).\n",
    "\n",
    "\n",
    "Tenga en cuenta que es común que un pequeño subconjunto de esos parámetros pueda tener un gran impacto en el rendimiento predictivo o de cálculo del modelo, mientras que otros pueden dejar sus valores predeterminados. Se recomienda leer la documentación de la clase de estimador para obtener una mejor comprensión de su comportamiento esperado, posiblemente leyendo la referencia adjunta a la literatura."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ftr35YoPkhEo"
   },
   "source": [
    "## GridSearchCV\n",
    "\n",
    "Una alternativa para seleccionar hiperparámetros es GridSearchCV, la cual considera exhaustivamente todas las combinaciones de parámetros. GridSearchCV recibe un *estimador*, recibe *param_grid* (un diccionario o una lista de diccionarios con los nombres de los parametros a probar como keys y una lista de los valores a probar), *scoring* una o varias funciones de puntuación (score) para evaluar cada combinación de parametros (opciones válidas: https://scikit-learn.org/stable/modules/model_evaluation.html) y *cv* una extrategia para hacer validación cruzada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KvtFRHnAvmYy"
   },
   "source": [
    "El siguiente código muestra cómo seleccionar el número de vecinos y qué pesos otorgar a los vecinos en un clasificador KNN. \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T16:37:11.054888Z",
     "start_time": "2020-05-25T16:37:10.392211Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3858,
     "status": "ok",
     "timestamp": 1569546376310,
     "user": {
      "displayName": "Juglar Díaz Zamora",
      "photoUrl": "",
      "userId": "09248297146704680040"
     },
     "user_tz": 180
    },
    "id": "Jme31lpTroM8",
    "outputId": "0f170208-2762-40a3-96a8-bcaf14f2f8c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor combinación de parámetros:\n",
      "{'n_neighbors': 5, 'weights': 'uniform'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.86      0.90        76\n",
      "           1       0.89      0.96      0.92        95\n",
      "\n",
      "    accuracy                           0.91       171\n",
      "   macro avg       0.92      0.91      0.91       171\n",
      "weighted avg       0.91      0.91      0.91       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.30)\n",
    "\n",
    "#Configure tuned_parameters\n",
    "tuned_parameters = {'n_neighbors': [1, 3, 5, 10], \n",
    "                    'weights': ['uniform','distance']}\n",
    "\n",
    "#set scoring metric\n",
    "score = 'precision' \n",
    "\n",
    "#Construir el clf con GridSearch\n",
    "clf = GridSearchCV(KNeighborsClassifier(), \n",
    "                   param_grid=tuned_parameters, \n",
    "                   cv=5,\n",
    "                   scoring=score)\n",
    "\n",
    "#Entrenar clf\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mejor combinación de parámetros:\")\n",
    "print(clf.best_params_)\n",
    " \n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-4avvyE6sNL6"
   },
   "source": [
    "## Pregunta 2.1\n",
    "\n",
    "*  a) Realice este mismo proceso para un clasificador DecisionTree y los parametros criterion=['gini','entropy'], max_depth=[2,4,10] y tomando como scoring metric 'f1'. Mantenga cv=5\n",
    "*  b) ¿Qué puede decir de los resultados, con cuáles parámetros los obtuvo? ¿Cuál considera que es la principal ventaja de aplicar GridSearchCV? ¿Considera que es necesario seguir explorando los parámetros?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T16:36:46.379125Z",
     "start_time": "2020-05-25T16:36:45.308Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 752,
     "status": "ok",
     "timestamp": 1569546628013,
     "user": {
      "displayName": "Juglar Díaz Zamora",
      "photoUrl": "",
      "userId": "09248297146704680040"
     },
     "user_tz": 180
    },
    "id": "oo1gdJeOrErl",
    "outputId": "7cfd76de-be2c-4190-d471-ec0533011614"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor combinación de parámetros:\n",
      "{'criterion': 'entropy', 'max_depth': 4}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        65\n",
      "           1       1.00      1.00      1.00       106\n",
      "\n",
      "    accuracy                           1.00       171\n",
      "   macro avg       1.00      1.00      1.00       171\n",
      "weighted avg       1.00      1.00      1.00       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## RESPUESTA A PREGUNTA 2.1 a)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.30)\n",
    "\n",
    "## COMPLETE ACÁ (guiarse con la sección anterior pero ahora con decision tree)\n",
    "#Configure tuned_parameters\n",
    "tuned_parameters = {'max_depth': [2, 4, 10], \n",
    "                    'criterion': ['gini','entropy']}\n",
    "\n",
    "#set scoring metric\n",
    "score = 'f1' \n",
    "\n",
    "#Construir el clf con GridSearch\n",
    "clf = GridSearchCV(DecisionTreeClassifier(), \n",
    "                   param_grid=tuned_parameters, \n",
    "                   cv=5,\n",
    "                   scoring=score)\n",
    "\n",
    "#Entrenar clf\n",
    "clf.fit(X_test,y_test)\n",
    "\n",
    "\n",
    "print(\"Mejor combinación de parámetros:\")\n",
    "print(clf.best_params_)\n",
    " \n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mF4uhT12yHLQ"
   },
   "source": [
    "### Respuesta 2.1 continuación b)\n",
    "\n",
    "::\n",
    "\n",
    "Los resultados tienen métricas perfectas con los siguientes parametros criterion='entropy', max_depth=4.\n",
    "\n",
    "La principal ventaja de aplicar GridSearchCV es que permite evaluar y seleccionar de forma sistemática los parámetros de un modelo, además de la posibilidad de probar múltiples hiperparámetros de los modelos (o conjunto de datos) a la vez. Se prueban diferentes valores que se evalúan con GridSearchCV.\n",
    "\n",
    "Es necesario seguir explorando parámetros en el caso de que se pueda hallar una mejor combinación de parámetros. En este caso, eso no es posible ya que se tiene todas las métricas en 1.0, es decir, métricas perfectas.\n",
    "\n",
    "::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p00ZnCRM4a8_",
    "pycharm": {}
   },
   "source": [
    "---\n",
    "\n",
    "# Parte 3: Tratando con clases desbalanceadas\n",
    "\n",
    "Para mejorar el rendimiento de un clasificador sobre clases desbalanceadas existen varias técnicas. En esta parte, veremos cómo tratar con este problema usando (sub/over) sampling de las clases.\n",
    "\n",
    "Descargue el dataset `unbalanced.csv` (sugerido en el tutorial 2). \n",
    "\n",
    "(*Nota: Para ejecutar el siguiente bloque es necesaria la librería `pandas` que viene incluida en Anaconda.*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T16:37:52.238333Z",
     "start_time": "2020-05-25T16:37:51.688487Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4803,
     "status": "ok",
     "timestamp": 1569546377355,
     "user": {
      "displayName": "Juglar Díaz Zamora",
      "photoUrl": "",
      "userId": "09248297146704680040"
     },
     "user_tz": 180
    },
    "id": "udOtwOQo4a9B",
    "outputId": "95b7c524-783a-4e0e-b094-234c7bdb9b0e",
    "pycharm": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>...</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>V29</th>\n",
       "      <th>V30</th>\n",
       "      <th>V31</th>\n",
       "      <th>V32</th>\n",
       "      <th>V33</th>\n",
       "      <th>V34</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>-0.17755</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>0.50874</td>\n",
       "      <td>-0.67743</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>0.73082</td>\n",
       "      <td>0.05346</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>0.52798</td>\n",
       "      <td>-0.20275</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        V3       V4       V5       V6       V7       V8       V9      V10  \\\n",
       "0  0.99539 -0.05889  0.85243  0.02306  0.83398 -0.37708  1.00000  0.03760   \n",
       "1  1.00000 -0.18829  0.93035 -0.36156 -0.10868 -0.93597  1.00000 -0.04549   \n",
       "2  1.00000 -0.03365  1.00000  0.00485  1.00000 -0.12062  0.88965  0.01198   \n",
       "3  1.00000 -0.45161  1.00000  1.00000  0.71216 -1.00000  0.00000  0.00000   \n",
       "4  1.00000 -0.02401  0.94140  0.06531  0.92106 -0.23255  0.77152 -0.16399   \n",
       "\n",
       "       V11      V12  ...      V26      V27      V28      V29      V30  \\\n",
       "0  0.85243 -0.17755  ... -0.51171  0.41078 -0.46168  0.21266 -0.34090   \n",
       "1  0.50874 -0.67743  ... -0.26569 -0.20468 -0.18401 -0.19040 -0.11593   \n",
       "2  0.73082  0.05346  ... -0.40220  0.58984 -0.22145  0.43100 -0.17365   \n",
       "3  0.00000  0.00000  ...  0.90695  0.51613  1.00000  1.00000 -0.20099   \n",
       "4  0.52798 -0.20275  ... -0.65158  0.13290 -0.53206  0.02431 -0.62197   \n",
       "\n",
       "       V31      V32      V33      V34  Class  \n",
       "0  0.42267 -0.54487  0.18641 -0.45300      0  \n",
       "1 -0.16626 -0.06288 -0.13738 -0.02447      1  \n",
       "2  0.60436 -0.24180  0.56045 -0.38238      0  \n",
       "3  0.25682  1.00000 -0.32382  1.00000      1  \n",
       "4 -0.05707 -0.59573 -0.04608 -0.65697      0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargamos dataset desbalanceado\n",
    "unbalanced_path = 'https://users.dcc.uchile.cl/~hsarmien/mineria/datasets/unbalanced.csv'\n",
    "data = pd.read_csv(unbalanced_path)  # abrimos el archivo csv y lo cargamos en data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LAXKVFfD4a9G",
    "pycharm": {}
   },
   "source": [
    "Note el desbalance de las clases ejecutando el siguiente código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T16:38:07.441014Z",
     "start_time": "2020-05-25T16:38:07.431991Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4759,
     "status": "ok",
     "timestamp": 1569546377357,
     "user": {
      "displayName": "Juglar Díaz Zamora",
      "photoUrl": "",
      "userId": "09248297146704680040"
     },
     "user_tz": 180
    },
    "id": "4qn9gsWy4a9H",
    "outputId": "0cb3cae6-97ef-4501-ba67-12e32b117b2c",
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribucion de clases original\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    225\n",
       "1    126\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Distribucion de clases original\")\n",
    "data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ee168t5vWIqG"
   },
   "source": [
    "Antes de hacer algo para tratar el desbalance entre las clases primero debemos dividir en train-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T16:38:26.896508Z",
     "start_time": "2020-05-25T16:38:26.888486Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "L88_th9fWaT2"
   },
   "outputs": [],
   "source": [
    "data_train, data_test, ytrain, ytest = train_test_split(data, data['Class'], test_size=0.3, stratify=data['Class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LaZWIUSvZ3ti"
   },
   "source": [
    "Así queda la proporción de clases en el train después de dividir en train-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T16:38:28.415746Z",
     "start_time": "2020-05-25T16:38:28.407725Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4704,
     "status": "ok",
     "timestamp": 1569546377359,
     "user": {
      "displayName": "Juglar Díaz Zamora",
      "photoUrl": "",
      "userId": "09248297146704680040"
     },
     "user_tz": 180
    },
    "id": "00j7PK-uZxJI",
    "outputId": "433d2f96-c7e6-4cde-962b-3296701f9b5c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    157\n",
       "1     88\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tch2wO604a9N",
    "pycharm": {}
   },
   "source": [
    "Ahora, usando el dataset anterior, aplicaremos **oversampling** y **subsampling** al train para que queden balanceados. Ejecute el siguiente código y note ahora que las clases están balanceadas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T16:38:43.621327Z",
     "start_time": "2020-05-25T16:38:43.600274Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4640,
     "status": "ok",
     "timestamp": 1569546377360,
     "user": {
      "displayName": "Juglar Díaz Zamora",
      "photoUrl": "",
      "userId": "09248297146704680040"
     },
     "user_tz": 180
    },
    "id": "Z6IViZylYvXc",
    "outputId": "885b88c6-1c9f-43c0-dade-f546966fc711"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de clases usando (over/sub) sampling\n",
      "\n",
      "Data oversampled on class '1'\n",
      "1    158\n",
      "0    157\n",
      "Name: Class, dtype: int64\n",
      "\n",
      "Data subsampled on class '0'\n",
      "1    88\n",
      "0    87\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"Distribución de clases usando (over/sub) sampling\")\n",
    "print()\n",
    "\n",
    "data_train = data_train.reset_index(drop=True)\n",
    "\n",
    "# oversampling sobre la clase 1\n",
    "idx = np.random.choice(data_train[data_train['Class'] == 1].index, size=70)\n",
    "data_oversampled = pd.concat([data_train, data_train.iloc[idx]])\n",
    "print(\"Data oversampled on class '1'\")\n",
    "print(data_oversampled['Class'].value_counts())\n",
    "print()\n",
    "\n",
    "\n",
    "# subsampling sobre la clase 0\n",
    "idx = np.random.choice(data_train.loc[data_train.Class == 0].index, size=70, replace=False)\n",
    "data_subsampled = data_train.drop(data_train.iloc[idx].index)\n",
    "print(\"Data subsampled on class '0'\")\n",
    "print(data_subsampled['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PtbC_00k4a9V",
    "pycharm": {}
   },
   "source": [
    "Vamos a entrenar un árbol de decisión (`DecisionTreeClassifier`) sobre los 3 datasets por separado (**original**, con **oversampling** y con **subsampling**) y luego comparamos los resultados usando alguna métrica de evaluación.\n",
    "\n",
    "Ejecute el siguiente bloque para cargar los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T16:39:03.845407Z",
     "start_time": "2020-05-25T16:39:03.832374Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "XNqgdSuk4a9W",
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "## ejecutar este código para preparar los datos\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Preparando los data frames para ser compatibles con sklearn\n",
    "\n",
    "# datos test (mismo para todos los conjuntos de entrenamiento)\n",
    "X_test = data_test[data_train.columns[:-1]] # todo hasta la penultima columna\n",
    "y_test = data_test[data_train.columns[-1]]  # la última columna\n",
    "\n",
    "\n",
    "# datos entrenamiento \"originales\"\n",
    "X_orig = data_train[data_train.columns[:-1]] \n",
    "y_orig = data_train[data_train.columns[-1]] \n",
    "\n",
    "# datos entrenamiento \"oversampleados\" \n",
    "X_over = data_oversampled[data_train.columns[:-1]]\n",
    "y_over = data_oversampled[data_train.columns[-1]]\n",
    "\n",
    "# datos entrenamiento \"subsampleados\"\n",
    "X_subs = data_subsampled[data_train.columns[:-1]]\n",
    "y_subs = data_subsampled[data_train.columns[-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "slTTwA4z4a9Y",
    "pycharm": {}
   },
   "source": [
    "**¿Por qué aplicar (sub/over) sampling de las clases sobre el conjunto de entrenamiento en lugar de aplicarlo sobre el dataset completo?**\n",
    "\n",
    "Para mantener la distribución natural de los datos que serán utilizados para evaluar el desempeño real del modelo. Si estos también fueran equilibrados, los resultados no indicarían cómo se desempeñaría el modelo con los datos reales. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se ejecuta el clasificador en cada uno de los tres casos, usando como datos de entrada lo del bloque anterior. Para cada caso se entrena con el dataset correspondiente y se evalúa con el conjunto de test (el mismo para los tres casos) obtenido con train_test_split sobre los datos originales. \n",
    "\n",
    "Se muestra Precision, Recall y F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-25T16:39:46.535743Z",
     "start_time": "2020-05-25T16:39:46.488620Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4551,
     "status": "ok",
     "timestamp": 1569546377363,
     "user": {
      "displayName": "Juglar Díaz Zamora",
      "photoUrl": "",
      "userId": "09248297146704680040"
     },
     "user_tz": 180
    },
    "id": "3HH9GqLY4a9c",
    "outputId": "08ccebe5-869d-4317-e977-37d3f216c787",
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL::::::::::\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93        68\n",
      "           1       0.94      0.79      0.86        38\n",
      "\n",
      "    accuracy                           0.91       106\n",
      "   macro avg       0.91      0.88      0.89       106\n",
      "weighted avg       0.91      0.91      0.90       106\n",
      "\n",
      "OVERSAMPLING::::::::::\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91        68\n",
      "           1       0.88      0.79      0.83        38\n",
      "\n",
      "    accuracy                           0.89       106\n",
      "   macro avg       0.89      0.87      0.87       106\n",
      "weighted avg       0.89      0.89      0.89       106\n",
      "\n",
      "SUBSAMPLING::::::::::\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.85      0.89        68\n",
      "           1       0.77      0.87      0.81        38\n",
      "\n",
      "    accuracy                           0.86       106\n",
      "   macro avg       0.84      0.86      0.85       106\n",
      "weighted avg       0.87      0.86      0.86       106\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## Pasos:\n",
    "##  - instanciar el clasificador con DecisionTreeClassifier()\n",
    "##  - entrenar con fit()\n",
    "##  - hacer las predicciones\n",
    "##  - mostrar precision, recall y f1-score con classification report.\n",
    "\n",
    "print(\"ORIGINAL::::::::::\")\n",
    "clf_orig = DecisionTreeClassifier()\n",
    "clf_orig.fit(X_orig, y_orig)\n",
    "pred_orig = clf_orig.predict(X_test)\n",
    "print(classification_report(y_test, pred_orig))\n",
    "\n",
    "print(\"OVERSAMPLING::::::::::\")\n",
    "clf_over = DecisionTreeClassifier()\n",
    "clf_over.fit(X_over, y_over)\n",
    "pred_over = clf_over.predict(X_test)\n",
    "print(classification_report(y_test, pred_over))\n",
    "\n",
    "print(\"SUBSAMPLING::::::::::\")\n",
    "clf_subs = DecisionTreeClassifier()\n",
    "clf_subs.fit(X_subs, y_subs)\n",
    "pred_subs = clf_subs.predict(X_test)\n",
    "print(classification_report(y_test, pred_subs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En promedio los resultados son similares para todas las estrategias, sin embargo, se puede ver la diferencia por clase. \n",
    "\n",
    "La estrategia oversampling presenta mejores resultados para la clase minoritaria (aunque puede que no siempre de mejor la misma estrategia). Esta estrategia de sampling ayuda a equilibrar las clases sin perder información, lo cual es útil, considerando que el dataset original es pequeño. \n",
    "\n",
    "Recuerde que F1-score es la métrica más conveniente para elegir la mejor estrategia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yMTUMsRn4a9k",
    "pycharm": {}
   },
   "source": [
    "## Pregunta 3.1\n",
    "\n",
    "Indique una desventaja de usar oversampling y una desventaja de usar subsampling en clasificación.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DhZKYD_M4a9m",
    "pycharm": {}
   },
   "source": [
    "### RESPUESTA A PREGUNTA 3.1\n",
    "::\n",
    "\n",
    "Una desventaja de subsampling es que puede que algunos datos nunca se usen para entrenar y/o puede que algunos datos nunca se usen para evaluar.\n",
    "\n",
    "Una desventaja de usar oversampling es que complejiza un modelo más de lo necesario, además de que se puede dar por ruido en los datos.\n",
    "\n",
    "::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "name": "lab2.2-PAUTA_CC5206_2019-2.ipynb",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
